{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6bbd079",
   "metadata": {},
   "source": [
    "### Reference\n",
    "[facenet in python](https://www.kaggle.com/code/yaraxavier/face-recognition-using-facenet)\n",
    "[facenet](https://www.kaggle.com/datasets/rmamun/kerasfaceneth5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00209cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "IMG_W, IMG_H, IMG_C = (160, 160, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e7c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/model/facenet_keras.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a686b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_embedding(image: np.ndarray, model) -> np.ndarray:\n",
    "    \"\"\"Generate face embedding for image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Image to generate encoding for.\n",
    "        model : Pretrained face recognition model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Face embedding for image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtain image encoding\n",
    "    embedding = model.predict(image[np.newaxis, ...])\n",
    "\n",
    "    # Normalize bedding using L2 norm.\n",
    "    embedding /= np.linalg.norm(embedding, ord=2)\n",
    "\n",
    "    # Return embedding\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(\n",
    "    embedding_1: np.ndarray, embedding_2: np.ndarray, threshold: float = 0.8\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Compares two embeddings and returns 1 if the distance between them is less than the threshold, else 0.\n",
    "\n",
    "    Args:\n",
    "    - embedding_1: A 128-dimensional embedding vector.\n",
    "    - embedding_2: A 128-dimensional embedding vector.\n",
    "    - threshold: A float value representing the maximum allowed distance between embeddings for them to be considered a match.\n",
    "\n",
    "    Returns:\n",
    "    - 1 if the distance between the embeddings is less than the threshold, else 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the distance between the embeddings\n",
    "    embedding_distance = embedding_1 - embedding_2\n",
    "\n",
    "    # Calculate the L2 norm of the distance vector\n",
    "    embedding_distance_norm = np.linalg.norm(embedding_distance)\n",
    "\n",
    "    # Return 1 if the distance is less than the threshold, else 0\n",
    "    return embedding_distance_norm if embedding_distance_norm < threshold else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(\n",
    "    image: np.ndarray,\n",
    "    image_to_compare: np.ndarray,\n",
    "    database: dict,\n",
    "    threshold: float = 1.0,\n",
    "    model=model,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Given an image, recognize the person in the image using a pre-trained model and a database of known faces.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image as a numpy array.\n",
    "        database (dict): A dictionary containing the embeddings of known faces.\n",
    "        threshold (float): The distance threshold below which two embeddings are considered a match.\n",
    "        model (keras.Model): A pre-trained Keras model for extracting image embeddings.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the recognized person, or \"No Match Found\" if no match is found.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embedding for the new image\n",
    "    image_emb = image_to_embedding(image, model)\n",
    "    image_to_compare_emb = image_to_embedding(image_to_compare, model)\n",
    "\n",
    "    dist = compare_embeddings(image_to_compare_emb, image_emb, threshold=threshold)\n",
    "\n",
    "    if dist != 0:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
